{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# if topographic is not installed, make sure to append the path\n",
    "sys.path.append('..')\n",
    "from topographic.utils.plotting.EI import plotting_pipeline\n",
    "from topographic.results import NAMED_MODELS\n",
    "from topographic.ITN import parse_model_args, unparse_model_args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying and loading specific models\n",
    "Models are specified by a base filename or `base_fn`. These filenames contain key-val_ pairs to specify relevant model hyperparameters. The name of the file can thus be used to reconstruct the model, and the model can be used to construct the file name. \n",
    "\n",
    "A dictionary of pre-trained file names (values) with shortened identifiers (keys) can be found in `topographic.results.NAMED_MODELS`\n",
    "\n",
    "If you want to see the hyper-parameters associated with this filename, you can use the `topographic.ITN.unparse_model_args` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = NAMED_MODELS['main_model']\n",
    "print(main_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = unparse_model_args(main_model, use_short_names=True)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to specifying models by their filename, you can specify a model by its set of keyword arguments \n",
    "\n",
    "The parsing function `topographic.ITN.parse_model_args` will start with a default dictionary of hyper-parameter values, and edit any that you specify. It then returns the `base_fn`, full set of hyperparameters `opt`, and keyword arguments to pass specifically into the ITN `arch_kwargs`.\n",
    "\n",
    "For example, let's say we want to take the main model and change the strength of spatial regularization $\\lambda_w$ to 0.1, and make the model process inputs in a feedforward fashion (one time step, no learned lateral processing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt['jjlam'] = 0.5\n",
    "# opt['timing'] = 'ff'\n",
    "# opt['norec'] = True\n",
    "opt['cell'] = 'EI5'\n",
    "base_fn, opt, arch_kwargs = parse_model_args(bools_as_ints=True, **opt)\n",
    "print(base_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the results of a given model\n",
    "We have created a plotting_pipeline function that will run a set of experiments and plot the results. The specifics of what is run can be modified using per-experiment kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "save = False # set to True to save figures to disk as .png files\n",
    "layers = ['aIT'] # set to [None] to automatically test all IT layers\n",
    "base_fn = main_model # feel free to change to something else, but you might have to first train the model\n",
    "\n",
    "# simply uncomment out the lines corresponding to an experiment you want to run\n",
    "kwargs_by_exp = dict(\n",
    "#     accuracy = dict(save=save),\n",
    "    maps = dict(save=save),\n",
    "#     lesioning = dict(save=save),\n",
    "    spatial_corrs = dict(save=save),\n",
    "#     localizers = dict(save=save, layers=layers),\n",
    "#     ei_columns = dict(save=save, layers=layers),\n",
    "#     rfs = dict(save=save),\n",
    "#     category_level = dict(save=save, plot_contours=False),\n",
    "    principal_components = dict(save=save, layers=layers, plot_contours=True),\n",
    "    )\n",
    "\n",
    "\n",
    "plotting_pipeline(base_fn, kwargs_by_exp, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending the analysis of a trained model\n",
    "If you want to run some of your own analyses rather than restricting yourself to the functions we have provided, you can easily load some useful information about a given model and then write code to analyze it however you wish. View the docstring and source code of `topographic.utils.plotting.EI.load_for_tests` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topographic.utils.plotting.EI import load_for_tests\n",
    "base_fn, opt, arch_kwargs, model, selectivity_results, accuracy, val_activations, domain_trials, searchlight_accuracies = load_for_tests(main_model, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?load_for_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:topographic]",
   "language": "python",
   "name": "conda-env-topographic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
