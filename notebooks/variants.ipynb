{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from topographic.utils.plotting.EI import compare_jj_lambdas\n",
    "from topographic.config import SAVE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models with different spatial penalties\n",
    "Here, we compare models of a given architecture at a range of $\\lambda_w$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = ['FNN', 'RNN', 'EFF-FNN', 'EFF-RNN', 'E/I-FNN', 'E/I-RNN', 'E/I-EFF-RNN']\n",
    "\n",
    "for arch in ['E/I-EFF-RNN']:\n",
    "    plt.close('all')\n",
    "    models = compare_jj_lambdas(\n",
    "        seed=1, \n",
    "        mod_id='jjd2', \n",
    "        mod_type=arch, \n",
    "        wrap=False, \n",
    "        lambdas=[0, 0.01, 0.1, 0.5, 1.0, 10.0], \n",
    "        do_performance=True, do_generic=False, do_domains=False, do_combined=True, do_summary=True, \n",
    "        show=True,\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models with different architectures\n",
    "Here, we compare architectures using the value of $\\lambda_w$ that produced the largest domain-level topographic summary statistic, with a new seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topographic.utils.plotting.EI import ei_ablations\n",
    "plt.close('all')\n",
    "\n",
    "models = ei_ablations(seed=2, jj=True, ln=True, wrap=False, subset=True, do_performance=True, do_generic=False, do_domains=False, do_combined=True, do_summary=True, show=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models with different architectures and spatial penalty\n",
    "Plots a wider range of metrics than before, including wiring cost, but does not perform visualizations. \n",
    "\n",
    "Note: this may take a while to run, which is why we save the results for all the models at the end of the first cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topographic.config import SAVE_DIR, FIGS_DIR\n",
    "from topographic.utils.commons import exp_times\n",
    "from topographic.utils.experiments import run_wiring_cost_experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topographic.utils.plotting.EI import compute_domain_summary_stat, compute_generic_summary_stat, get_binary_selectivity, load_for_tests\n",
    "import os\n",
    "from topographic.config import SAVE_DIR\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "seed=1\n",
    "ln=True\n",
    "wrap=False\n",
    "mod_types=['E/I-EFF-RNN', 'EFF-RNN', 'E/I-RNN', 'RNN', 'EFF-FNN', 'E/I-FNN', 'FNN']\n",
    "lambdas=[0, 0.001, 0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "layers=['pIT', 'cIT', 'aIT']\n",
    "\n",
    "stat_types = [1,2]\n",
    "time='exp_end'\n",
    "celltypes = ['', '_I']\n",
    "binary_map_smoothing = 0\n",
    "neglogp_thresh=3\n",
    "overwrite_df = False\n",
    "\n",
    "model_dict = {'arch':[], 'lambda':[], 'base_fn':[], 'generic_stat':[], 'final accuracy':[], 'final top5 accuracy':[], 'jj_ff':[], 'jj_rec':[]}\n",
    "for stat_type in stat_types:\n",
    "    model_dict[f'domain_stat_{stat_type}'] = []\n",
    "for layer in layers:\n",
    "    model_dict[f'{layer}_topography'] = []\n",
    "for sparsity in [0.01, 0.05, 0.1]:\n",
    "    model_dict[f'cost_at_{sparsity}'] = []\n",
    "    model_dict[f'rec_cost_at_{sparsity}'] = []\n",
    "    model_dict[f'ff_cost_at_{sparsity}'] = []\n",
    "    model_dict[f'acc_at_{sparsity}'] = []\n",
    "    \n",
    "wrap_tag = '_nwr-1' if not wrap else ''\n",
    "ln_tag = 'noln' if not ln else '' \n",
    "mod_id = 'jjd2'+ln_tag\n",
    "\n",
    "os.makedirs(f'{SAVE_DIR}/dfs', exist_ok=True)\n",
    "save_file =  f'{SAVE_DIR}/dfs/full_ablations{ln_tag}_results.pkl'\n",
    "\n",
    "if not os.path.exists(save_file) or overwrite_df:\n",
    "\n",
    "    for mod_type in mod_types:\n",
    "        if mod_type == 'E/I-EFF-RNN':\n",
    "            temp_fn = 'a-0.2_cIT-1_cell-EI4_conn-full_ar-1.0_enc-resnet50_err-1_fsig-5.0_gc-10.0_i2e-1.0_id-{}_imd-112{}_lr0-0.01_me-300_ms-32_nl-relu_noi-uniform_nret-1{}_optim-sgd_rv4-1_rs-{}_rsig-5.0_sch-plateau_sq-1_t-v3_tr-miniOFS'\n",
    "        elif mod_type == 'EFF-RNN':\n",
    "            temp_fn = 'a-0.2_cIT-1_cell-SRNEFF_conn-full_ar-1.0_enc-resnet50_err-1_fsig-5.0_gc-10.0_i2e-1.0_id-{}_imd-112{}_lr0-0.01_me-300_ms-32_nl-relu_noi-uniform_nret-1{}_optim-sgd_rv4-1_rs-{}_rsig-5.0_sch-plateau_sq-1_t-v3_tr-miniOFS'\n",
    "        elif mod_type == 'E/I-RNN':\n",
    "            temp_fn = 'a-0.2_cIT-1_cell-EI5_conn-full_ar-1.0_enc-resnet50_err-1_fsig-5.0_gc-10.0_i2e-1.0_id-{}_imd-112{}_lr0-0.01_me-300_ms-32_nl-relu_noi-uniform_nret-1{}_optim-sgd_rv4-1_rs-{}_rsig-5.0_sch-plateau_sq-1_t-v3_tr-miniOFS'\n",
    "        elif mod_type == 'RNN':\n",
    "            temp_fn = 'a-0.2_cIT-1_cell-SRN_conn-full_ar-1.0_enc-resnet50_err-1_fsig-5.0_gc-10.0_i2e-1.0_id-{}_imd-112{}_lr0-0.01_me-300_ms-32_nl-relu_noi-uniform_nret-1{}_optim-sgd_rv4-1_rs-{}_rsig-5.0_sch-plateau_sq-1_t-v3_tr-miniOFS'\n",
    "        elif mod_type == 'EFF-FNN':\n",
    "            temp_fn = 'a-1.0_cIT-1_cell-SRNEFF_conn-full_ar-1.0_enc-resnet50_err-1_fsig-5.0_gc-10.0_i2e-1.0_id-{}_imd-112{}_lr0-0.01_me-300_ms-32_nl-relu_noi-uniform_nret-1_norec-1{}_optim-sgd_rv4-1_rs-{}_rsig-5.0_sch-plateau_sq-1_t-ff_tr-miniOFS'\n",
    "        elif mod_type == 'E/I-FNN':\n",
    "            temp_fn = 'a-1.0_cIT-1_cell-EI5_conn-full_ar-1.0_enc-resnet50_err-1_fsig-5.0_gc-10.0_i2e-1.0_id-{}_imd-112{}_lr0-0.01_me-300_ms-32_nl-relu_noi-uniform_nret-1_norec-1{}_optim-sgd_rv4-1_rs-{}_rsig-5.0_sch-plateau_sq-1_t-ff_tr-miniOFS'\n",
    "        elif mod_type == 'FNN':\n",
    "            temp_fn = 'a-1.0_cIT-1_cell-SRN_conn-full_ar-1.0_enc-resnet50_err-1_fsig-5.0_gc-10.0_i2e-1.0_id-{}_imd-112{}_lr0-0.01_me-300_ms-32_nl-relu_noi-uniform_nret-1_norec-1{}_optim-sgd_rv4-1_rs-{}_rsig-5.0_sch-plateau_sq-1_t-ff_tr-miniOFS'\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        for lam in lambdas:\n",
    "            jj_tag = f'_jj-{lam}' if lam else ''\n",
    "            jj_name = r'$\\lambda=$' + str(lam)\n",
    "\n",
    "            full_fn = temp_fn.format(mod_id, jj_tag, wrap_tag, seed)\n",
    "            # first check it exists\n",
    "            if not os.path.exists(f'{SAVE_DIR}/results/{full_fn}_losses.pkl'):\n",
    "                print(f'{full_fn} does not exist')\n",
    "                continue\n",
    "            # now check to make sure model finished, which we will do by looking at the final learning rate\n",
    "            sd = torch.load(f'{SAVE_DIR}/models/{full_fn}.pkl')\n",
    "            if sd[2]['_last_lr'][0] != 1e-05:\n",
    "                print(f'{full_fn} not done')\n",
    "                continue\n",
    "\n",
    "            outputs = load_for_tests(full_fn, as_dict=True)\n",
    "            timing = exp_times[outputs['opt']['timing']]\n",
    "            t = getattr(timing, time)\n",
    "            res = outputs['res']\n",
    "            these_generic_stats = []\n",
    "\n",
    "            for si, stat_type in enumerate(stat_types):\n",
    "                these_domain_stats = []\n",
    "                for layer in layers:\n",
    "                    for celltype in celltypes:\n",
    "                        if 'EI' not in outputs['opt']['cell'] and celltype == '_I':\n",
    "                            continue\n",
    "                        dists = getattr(outputs['model'], layer).rec_distances[:outputs['opt'].ms**2,:outputs['opt'].ms**2]\n",
    "                        selectivity_dict = {domain: res.iloc[np.logical_and.reduce((res.t == t-1, res.layer == layer))][f'{domain}_selectivity_neglogp{celltype}'].iloc[0] for domain in ['object', 'face', 'scene']}\n",
    "                        domain_stat = compute_domain_summary_stat(selectivity_dict, dists, outputs['opt'].ms, celltype, stat_type=stat_type, binary_map_smoothing=binary_map_smoothing)\n",
    "                        these_domain_stats.append(domain_stat)\n",
    "                        activations = outputs['acts'][layer][:, t-1] # don't select celltype units, as this is done inside helper function\n",
    "                        if si == 0:\n",
    "                            # super hacky way to only do this once\n",
    "                            generic_stat = compute_generic_summary_stat(activations, dists, outputs['opt']['ms'], celltype, plot=False)\n",
    "                            these_generic_stats.append(generic_stat)\n",
    "                model_dict[f'domain_stat_{stat_type}'].append(np.nanmean(these_domain_stats))\n",
    "\n",
    "            model_dict['base_fn'].append(full_fn)\n",
    "            model_dict['arch'].append(mod_type)\n",
    "            model_dict['lambda'].append(lam)\n",
    "            model_dict['generic_stat'].append(np.nanmean(these_generic_stats))\n",
    "            for layer in layers:\n",
    "                distances = getattr(outputs['model'], layer).rec_distances[:outputs['opt'].ms**2,:outputs['opt'].ms**2]\n",
    "                colored_map, cmap = get_binary_selectivity(res, t, distances, layer, ms=outputs['opt'].ms, smoothing_p=binary_map_smoothing, neglogp_thresh=neglogp_thresh)\n",
    "                model_dict[f'{layer}_topography'].append(colored_map)\n",
    "\n",
    "            if os.path.exists(f'{SAVE_DIR}/results/{full_fn}_wiring_cost.pkl'): \n",
    "                jj_losses = np.load(f'{SAVE_DIR}/results/{full_fn}_wiring_cost.pkl',allow_pickle=True)\n",
    "                model_dict['jj_rec'].append(jj_losses['rec'])\n",
    "                model_dict['jj_ff'].append(jj_losses['ff'])\n",
    "\n",
    "            else:\n",
    "                for conn_type in ['ff', 'rec']:\n",
    "                    jj_loss = 0\n",
    "                    for param, dists in outputs['model'].spatial_params(subcells=[conn_type]):\n",
    "                        if 'jjl2' in getattr(outputs['model'], outputs['model'].cells[-1]).cell.modid:\n",
    "                            jj_loss += torch.sum((param**2)*dists/(1+param**2))\n",
    "                        elif 'jjd2' in getattr(outputs['model'], outputs['model'].cells[-1]).cell.modid:\n",
    "                            jj_loss += torch.sum((param**2)*(dists**2)/(1+param**2))\n",
    "                        else:\n",
    "                            jj_loss += torch.sum(torch.abs(param)*dists)\n",
    "                    model_dict[f'jj_{conn_type}'].append(jj_loss.item())\n",
    "            # now compute sparse binary wiring cost\n",
    "            wiring_results = run_wiring_cost_experiment(full_fn, \n",
    "                                        sparsity_vals=[0.01],\n",
    "                                        analysis_times=np.unique([timing.stim_off, timing.exp_end, timing.exp_end+timing.jitter]),\n",
    "                                        alg='l2',\n",
    "                                        local_pruning=True,\n",
    "                                        inputs_and_outputs=False,\n",
    "                                        overwrite=False,\n",
    "                                        overwrite_indiv_results=False, overwrite_indiv_exp=False,\n",
    "\n",
    "            )\n",
    "            wiring_results = pd.DataFrame(wiring_results)\n",
    "            for sparsity in [0.01]:\n",
    "                model_dict[f'cost_at_{sparsity}'].append(wiring_results[wiring_results.sparsity==sparsity].wiring_cost.mean())\n",
    "                model_dict[f'rec_cost_at_{sparsity}'].append(wiring_results[wiring_results.sparsity==sparsity].wiring_cost_rec.mean())\n",
    "                model_dict[f'ff_cost_at_{sparsity}'].append(wiring_results[wiring_results.sparsity==sparsity].wiring_cost_ff.mean())\n",
    "                model_dict[f'acc_at_{sparsity}'].append(wiring_results[np.logical_and(wiring_results.t==timing.exp_end, wiring_results.sparsity==sparsity)].accuracy.mean())\n",
    "\n",
    "            with open(f'{SAVE_DIR}/results/{full_fn}_losses.pkl', 'rb') as f:\n",
    "                these_losses = pickle.load(f)\n",
    "            model_dict['final accuracy'].append(these_losses['val']['acc'][-1])\n",
    "            model_dict['final top5 accuracy'].append(these_losses['val']['top5'][-1])\n",
    "\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(model_dict, f)\n",
    "else:\n",
    "    with open(save_file, 'rb') as f:\n",
    "        model_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "from topographic.config import FIGS_DIR\n",
    "\n",
    "with open(f'full_ablations{ln_tag}_results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_dict, f)\n",
    "    \n",
    "save_dir = f'{FIGS_DIR}/topographic/EI/experiments/arch_by_lambda{ln_tag}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(model_dict)\n",
    "df = df[df['lambda'] != 0.001]\n",
    "df['jj'] = df['jj_rec'] + df['jj_ff']\n",
    "df['jj_rec'][['FNN' in arch for arch in df.arch]] = np.nan\n",
    "\n",
    "for stat, ylabel in [\n",
    "    ('generic_stat', r'Generic topography ($T_g$)'), \n",
    "    ('domain_stat_2', r'Domain topography ($T_d$)'), \n",
    "    ('final accuracy', 'Accuracy'), \n",
    "    ('acc_at_0.01', 'Accuracy at s=0.99'), \n",
    "    ('cost_at_0.01', 'Average connection $d^2$ (s=0.99)'),\n",
    "    ('jj', '$\\mathcal{L}_w$')\n",
    "]:\n",
    "# for stat in ['cost_at_0.01', 'jj_ff', 'jj_rec', 'jj']:\n",
    "    # fig, axs = plt.subplots(1,2,sharey=True)\n",
    "    fig = plt.figure()\n",
    "    gs = gridspec.GridSpec(1,2,width_ratios=[1,5])\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax2 = fig.add_subplot(gs[1], sharey=ax1)\n",
    "    # ax1 = plt.subplot2grid((4,1),(0,0))\n",
    "    # ax2 = plt.subplot2grid((4,1),(0,1), colspan=3)\n",
    "    axs = [ax1, ax2]\n",
    "    kwargs = dict(markersize=7, linewidth=1) if stat in ['cost_at_0.01', 'jj_ff', 'jj_rec', 'jj'] else dict(markersize=10, linewidth=1)\n",
    "    g = sns.lineplot(data=df[df['lambda'] == 0], ax=axs[0], legend=False, hue_order=['E/I-EFF-RNN', 'E/I-RNN', 'E/I-FNN', 'EFF-RNN', 'EFF-FNN', 'RNN', 'FNN'],\n",
    "                     x='lambda', y=stat, hue='arch', style='arch', markers=True, dashes=False,\n",
    "                     **kwargs,\n",
    "                    )\n",
    "    g = sns.lineplot(data=df[df['lambda'] != 0], ax=axs[1], hue_order=['E/I-EFF-RNN', 'E/I-RNN', 'E/I-FNN', 'EFF-RNN', 'EFF-FNN', 'RNN', 'FNN'],\n",
    "                     x='lambda', y=stat, hue='arch', style='arch', markers=True, dashes=False,\n",
    "                     **kwargs,\n",
    "                    )\n",
    "    axs[1].set_xscale('log')\n",
    "    axs[0].set_xlim([-0.01, 0.01])\n",
    "    axs[0].set_xticks([0])\n",
    "    axs[0].spines['right'].set_visible(False)\n",
    "    axs[0].set_xlabel('')\n",
    "    axs[0].set_ylabel(ylabel)\n",
    "    axs[1].spines['left'].set_visible(False)\n",
    "    axs[1].set_ylabel('')\n",
    "    axs[1].set_xlabel(r'$\\lambda_w$')\n",
    "    axs[1].legend(bbox_to_anchor=(1.05, 0.8), loc=2, borderaxespad=0.)\n",
    "    if stat in ['jj_rec', 'jj_ff', 'cost_at_0.01', 'jj']:\n",
    "        axs[1].set_yscale('log')\n",
    "#         axs[1].set_aspect('equal', adjustable='datalim', share=True)\n",
    "#         axs[1].set_xscale('log') # do it again..\n",
    "    plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/{stat}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:topographic]",
   "language": "python",
   "name": "conda-env-topographic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
